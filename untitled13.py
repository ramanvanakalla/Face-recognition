# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DwkaCTgi0IkLs_-57OJJPOGAUv9YNTTm
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install mtcnn

!pip install git+https://github.com/rcmalli/keras-vggface.git

from numpy import expand_dims
from matplotlib import pyplot
import pickle
import numpy as np
from PIL import Image
from numpy import asarray
from mtcnn.mtcnn import MTCNN
from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input
from keras_vggface.utils import decode_predictions
from keras import Sequential
from scipy.spatial import distance

import mtcnn
from mtcnn.mtcnn import MTCNN


detector=MTCNN()
def extract_face(filename, required_size=(224, 224)):
  print(filename)
  pixels = pyplot.imread(filename)
  detector = MTCNN()
  results = detector.detect_faces(pixels)
  x1, y1, width, height = results[0]['box']
  x2, y2 = x1 + width, y1 + height
  face = pixels[y1:y2, x1:x2]
  image = Image.fromarray(face)
  image = image.resize(required_size)
  face_array = asarray(image)
  return face_array


def get_embeddings(filenames):
  faces = [extract_face(f) for f in filenames]
  print("Done")
  samples = asarray(faces, 'float32')
  samples = preprocess_input(samples, version=2)
  model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')
  yhat = model.predict(samples)
  return yhat

Image.open('/content/drive/My Drive/Datasheet/VIP Customer/VC59.jpg')

employee_list=[]

for i in range(1,210+1):
  employee_list.append('/content/drive/My Drive/Datasheet/Employees/'+'E'+str(i)+'.jpg')
  
print(employee_list)

customer_list=[]

for i in range(1,210+1):
  customer_list.append('/content/drive/My Drive/Datasheet/Normal Customer/'+'C'+str(i)+'.jpg')
  
print(customer_list)

vip_list=[]

for i in range(1,180+1):
  vip_list.append('/content/drive/My Drive/Datasheet/VIP Customer/'+'VC'+str(i)+'.jpg')
  
print(vip_list)

a=get_embeddings(employee_list)

b=get_embeddings(customer_list)

c=get_embeddings(vip_list)

a=get_embeddings(['1.jpg','2.jpg','3.jpg','4.jpg','5.jpg'])

#dbfile = open('newEmb', 'ab') 
#pickle.dump(a, dbfile)                      
#dbfile.close()

b=get_embeddings(['10.jpg','20.jpg','30.jpg','40.jpg','50.jpg'])

for i in range(len(b)):
  print(i)
  for j in range(len(a)):
     if(distance.cosine(b[i],a[j])<0.5):
          print("Matched ",j)
        
c=get_embeddings(['100.jpg','200.jpg','300.jpg','400.jpg','500.jpg'])

for i in range(len(c)):
  print(i)
  for j in range(len(a)):
     if(distance.cosine(c[i],a[j])<0.5):
          print("Matched ",j)

print(np.shape(a))
print(np.shape(b))
print(np.shape(c))

X=[]
Y=[]

for i in a:
  X.append(i)
  Y.append([1,0,0])
  
for i in b:
  X.append(i)
  Y.append([0,1,0])
  
for i in c:
  X.append(i)
  Y.append([0,0,1])

print(np.shape(Y))

from keras.optimizers import Adam

from keras.models import Sequential
from keras.layers import Dense

model=Sequential()
model.add(Dense(128,activation='relu',input_shape=(2048,)))
model.add(Dense(3,activation='sigmoid'))
model.summary()

model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False),metrics=['accuracy'])

history = model.fit(np.array(X),np.array(Y),epochs=25,verbose=1)

employee_test=[]

for i in range(1,7+1):
  employee_test.append('/content/drive/My Drive/Datasheet/NAME/'+'EMP'+str(i)+'.jpg')
  
print(employee_test)

customer_test=[]

for i in range(1,7+1):
  customer_test.append('/content/drive/My Drive/Datasheet/NAME/'+'CS'+str(i)+'.jpg')
  
print(customer_test)

vip_test=[]

for i in range(1,6+1):
  vip_test.append('/content/drive/My Drive/Datasheet/NAME/'+'CSV'+str(i)+'.jpg')
  
print(vip_test)

at=get_embeddings(employee_test)

bt=get_embeddings(customer_test)

ct=get_embeddings(vip_test)

X_test=[]
Y_test=[]

for i in at:
  X_test.append(i)
  Y_test.append([1,0,0])
  
for i in bt:
  X_test.append(i)
  Y_test.append([0,1,0])
  
for i in ct:
  X_test.append(i)
  Y_test.append([0,0,1])

model2.evaluate(np.array(X_test),np.array(Y_test),verbose=1)

